{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nassi\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:41: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6704 entries, 0 to 6703\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0             6704 non-null int64\n",
      "Unnamed: 0.1           6704 non-null int64\n",
      "ProjectID              6704 non-null object\n",
      "Project_Title          6703 non-null object\n",
      "Project_Story          6703 non-null object\n",
      "Project_Title_Scrap    6703 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 314.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Description of steps:\n",
    "# 1. Import existing dataset of indiegogo and create a new dataset which will be used\n",
    "#    to store the scraped information.\n",
    "# 2. By assigning each unique project URL to the chromedriver, beautiful soup scraps\n",
    "#    the information we want. The class which is identified was found by inspecting\n",
    "#    a random indiegogo project webpage - CTRL + SHIFT + I in Chrome. \n",
    "# 3. Iterate the above process for all projects available by using the project ID\n",
    "# 4. Create updated dataset by adding the new information extracted to the old dataset.\n",
    "# 5. Export excel file with the new information.\n",
    "\n",
    "# I used anaconda prompt for python to download all packages first. \n",
    "# Language: Python 3.6.\n",
    "\n",
    "# Import all libraries.\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import xlsxwriter\n",
    "\n",
    "# Import the dataset - it needs to be on the same folder as the python document.\n",
    "old_indiegogo = pd.read_excel('MERGED_FINAL1.xlsx')\n",
    "\n",
    "# Create new dataset which will be used to include the scraped information.\n",
    "new_indiegogo = old_indiegogo\n",
    "new_indiegogo['Project_Story'] = new_indiegogo['Project_Title']\n",
    "new_indiegogo['Project_Title_Scrap'] = new_indiegogo['Project_Title']\n",
    "new_indiegogo['ProjectID'] = new_indiegogo.ProjectID.astype(str)\n",
    "    \n",
    "# Open driver by adding the path where its located on the computer.\n",
    "driverPath = 'C:/Users/nassi/Desktop/chromedriver.exe'\n",
    "    \n",
    "# Create the options of the chrome driver which will be used in\n",
    "# a later stage for better use.\n",
    "options = webdriver.ChromeOptions()\n",
    "    \n",
    "# When scraping each webpage do not open the browser.\n",
    "options.add_argument(\"headless\")\n",
    "    \n",
    "# Use the above information to define the driver which will scrap the data.\n",
    "driver = webdriver.Chrome(executable_path=driverPath, chrome_options=options)\n",
    "\n",
    "new_indiegogo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row of our new data set and by indexing\n",
    "# the project ID, scrap the respective webpage.\n",
    "\n",
    "for index, row in new_indiegogo.iterrows():\n",
    "    \n",
    "    # The ID needs to be a string in order to be identified as part of\n",
    "    # the URL.\n",
    "    project_id = str(row['ProjectID'])\n",
    "    \n",
    "    url = 'https://www.indiegogo.com/projects/' + project_id\n",
    "    \n",
    "    # Run each unique URL with the driver.\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait only 4 seconds.\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # Create beautiful Soup object for scraping.\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    # Create object which includes only the information under the \n",
    "    # class: routerContentStory-storyBody. \n",
    "    # Convert to string in order to perform slicing.\n",
    "    content = str(soup.find('div', {'class': 'routerContentStory-storyBody'}))\n",
    "    title = str(soup.find('div', {'class': 'basicsSection-title fullhd t-h3--sansSerif'}))\n",
    "\n",
    "    # Remove all HTML/CSS commands.\n",
    "    while content.find('<')!=-1 and content.find('>')!=-1:\n",
    "        content = content[:content.find('<')] + content[content.find('>') + 1:]\n",
    "            \n",
    "    while title.find('<')!=-1 and title.find('>')!=-1:\n",
    "        title = title[:title.find('<')] + title[title.find('>') + 1:]\n",
    "        \n",
    "    # Further \"prettify\" by removing unnecessary characters.\n",
    "    content_new = ''.join(content)\n",
    "    content_new = content_new.replace(', ' , '')\n",
    "    content_new = content_new.replace('[' , '')\n",
    "    content_new = content_new.replace(']' , '')\n",
    "    content_new = content_new.replace('  ' , '')\n",
    "    content_new = content_new.replace('\\n' , ' ')\n",
    "    \n",
    "    title_new = ''.join(title)\n",
    "    title_new = title_new.replace('  ' , '')\n",
    "    # Remove Indiegogo unecessary extra comment\n",
    "       \n",
    "    # Add content to each unique projects 'Project_Story'.\n",
    "    row['Project_Story'] = content_new\n",
    "    row['Project_Title_Scrap'] = str(title_new).strip()\n",
    "\n",
    "# Create final_indiegogo.xlsx document in which the final data for all projects will be added.\n",
    "writer = pd.ExcelWriter('MERGED_FINAL1_1.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "new_indiegogo.to_excel(writer)\n",
    "\n",
    "# Output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
